%--------RESEARCH------------
\section{Publications}
 \resumeSubHeadingListStart
    \item
      {Baldassarre, M. T., Ernst, N., Hermann, B., Menzies, T., \& \textbf{Yedida, R.} (2023). (Re)use of Research Results (is Rampant). \textit{Communications of the ACM, 66(2), 75-81}.
      }
    \item
      {\textbf{Yedida, R.}, Kang, H. J., Tu, K., Lo, D., \& Menzies, T. (2023). How to Find Actionable Static Analysis Warnings: A Case Study with FindBugs. \textit{IEEE Transactions on Software Engineering, (01), 1-17}.}
    \item
      {\textbf{Yedida, R.}, Menzies, T. (2022). How to Improve Deep Learning for Software Analytics (a case study with code smell detection). In \textit{2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR). IEEE, 2022.}}
    \item
      {\textbf{Yedida, R.}, Krishna, R., Kalia, A., Menzies, T., Xiao, J., \& Vukovic, M. (2022). An Expert System for Redesigning Software for Cloud Applications. \textit{arXiv preprint arXiv:2109.14569}.}
    \item
      {\textbf{Yedida, R.}, \& Saha, S. (2021). Beginning with Machine Learning: A Comprehensive Primer. \textit{The European Physical Journal Special Topics: 1-82.}}
    \item
      {Agrawal, A., Yang, X., Agrawal, R., \textbf{Yedida, R.}, Shen, X., \& Menzies, T. (2021). Simpler Hyperparameter Optimization for Software Analytics: Why, How, When?. \textit{IEEE Transactions on Software Engineering, doi: 10.1109/TSE.2021.3073242}}
    \item
      {Yang, X., Chen, J., \textbf{Yedida, R.}, Yu, Z., \& Menzies, T. (2021). Learning to recognize actionable static code warnings (is intrinsically easy). \textit{Empirical Software Engineering, 26(3), 1-24}.}
    \item
      {\textbf{Yedida, R.}, \& Menzies, T. (2021). On the Value of Oversampling for Deep Learning in Software Defect Prediction. \textit{IEEE Transactions on Software Engineering, doi: 10.1109/TSE.2021.3079841}}
    \item
      {\textbf{Yedida, R.}, Krishna, R., Kalia, A., Menzies, T., Xiao, J., \& Vukovic, M. (2021). Lessons learned from hyper-parameter tuning for microservice candidate identification. \textit{Proceedings of the thirty-sixth IEEE/ACM International Conference on Automated Software Engineering (ASE)}.
      }
    \item
      {\textbf{Yedida, R.}, Yang, X., \& Menzies, T. (2021). Old but Gold: Reconsidering the value of feedforward learners for software analytics. \textit{arXiv preprint arXiv:2101.06319}.}
    \item
      {Saha, S., Nagaraj, N., Mathur, A., \textbf{Yedida, R.}, \& Sneha, H. R. (2020). Evolution of novel activation functions in neural network training for astronomy data: habitability classification of exoplanets. \textit{The European Physical Journal Special Topics, 229(16), 2629-2738}.}
    \item
      {\textbf{Yedida, R.}, Michael-Beasly, J., Korn, D., Abrar, S. M., Melo-Filho, C., Muratov, E., Graedon, J., Graedon, T., Chirkova, R., \& Tropsha, A. (2020). Text Mining of the People's Pharmacy Radio Show Transcripts Can Identify Novel Drug Repurposing Hypotheses. \textit{arXiv preprint arXiv:2011.07959}.}
    \item
      {\textbf{Yedida, R.}, Saha, S., \& Prashanth, T. (2020). LipschitzLR: Using theoretically computed adaptive learning rates for fast convergence. \textit{Applied Intelligence, 1-19}.}
    \item
      {Sridhar, S., Saha, S., Shaikh, A., \textbf{Yedida, R.}, \& Saha, S. (2020, July). Parsimonious Computing: A Minority Training Regime for Effective Prediction in Large Microarray Expression Data Sets. In \textit{2020 International Joint Conference on Neural Networks (IJCNN) (pp. 1-8). IEEE}.}
    \item
      {Khaidem, L., \textbf{Yedida, R.}, \& Theophilus, A. J. (2019, November). Optimizing Inter-nationality of Journals: A Classical Gradient Approach Revisited via Swarm Intelligence. In \textit{International Conference on Modeling, Machine Learning and Astronomy (pp. 3-14). Springer, Singapore}.}
 \resumeSubHeadingListEnd